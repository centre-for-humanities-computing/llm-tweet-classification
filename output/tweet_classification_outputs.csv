,precision,recall,f1-score,support,models,tasks,columns
exemplar,0.25380931649978233,0.7601043024771839,0.38054830287206265,767.0,google-flan-t5-xxl,few-shot,exemplar
not an exemplar,0.6897133220910624,0.19265190767781443,0.3011782032400589,2123.0,google-flan-t5-xxl,few-shot,exemplar
accuracy,0.34325259515570933,0.34325259515570933,0.34325259515570933,0.34325259515570933,google-flan-t5-xxl,few-shot,exemplar
macro avg,0.47176131929542237,0.4763781050774991,0.3408632530560608,2890.0,google-flan-t5-xxl,few-shot,exemplar
weighted avg,0.5740253039981518,0.34325259515570933,0.32224286290017895,2890.0,google-flan-t5-xxl,few-shot,exemplar
exemplar,0.2625139043381535,0.917098445595855,0.4081867973479389,772.0,BAAI-bge-large-en,zero-shot,exemplar
not an exemplar,0.6847290640394089,0.06531954887218046,0.11926211926211926,2128.0,BAAI-bge-large-en,zero-shot,exemplar
accuracy,0.2920689655172414,0.2920689655172414,0.2920689655172414,0.2920689655172414,BAAI-bge-large-en,zero-shot,exemplar
macro avg,0.47362148418878125,0.49120899723401773,0.26372445830502905,2900.0,BAAI-bge-large-en,zero-shot,exemplar
weighted avg,0.5723324766982472,0.2920689655172414,0.19617586115255123,2900.0,BAAI-bge-large-en,zero-shot,exemplar
apolitical,0.8951048951048951,0.5296551724137931,0.6655112651646448,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
political,0.6660137120470128,0.9379310344827586,0.7789232531500573,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
accuracy,0.7337931034482759,0.7337931034482759,0.7337931034482759,0.7337931034482759,stabilityai-StableBeluga-13B,zero-shot,political
macro avg,0.7805593035759539,0.7337931034482759,0.722217259157351,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
weighted avg,0.7805593035759539,0.7337931034482759,0.7222172591573509,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
exemplar,0.38248502994011974,0.666232073011734,0.48597242035187826,767.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
not an exemplar,0.8352638352638353,0.6113989637305699,0.7060103345118304,2123.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
accuracy,0.6259515570934256,0.6259515570934256,0.6259515570934256,0.6259515570934256,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
macro avg,0.6088744326019775,0.6388155183711519,0.5959913774318544,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
weighted avg,0.7150972803561225,0.6259515570934256,0.6476127289198984,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
exemplar,0.3826879271070615,0.4380704041720991,0.40851063829787226,767.0,BAAI-bge-large-en,few-shot,exemplar
not an exemplar,0.7857852882703777,0.7447008949599623,0.7646916565900845,2123.0,BAAI-bge-large-en,few-shot,exemplar
accuracy,0.6633217993079584,0.6633217993079584,0.6633217993079584,0.6633217993079584,BAAI-bge-large-en,few-shot,exemplar
macro avg,0.5842366076887197,0.5913856495660307,0.5866011474439784,2890.0,BAAI-bge-large-en,few-shot,exemplar
weighted avg,0.6788040854979682,0.6633217993079584,0.6701619538114939,2890.0,BAAI-bge-large-en,few-shot,exemplar
apolitical,0.6684755796743956,0.9377162629757786,0.7805299539170507,1445.0,BAAI-bge-large-en,few-shot,political
political,0.895712630359212,0.5349480968858131,0.669844020797227,1445.0,BAAI-bge-large-en,few-shot,political
accuracy,0.7363321799307958,0.7363321799307958,0.7363321799307958,0.7363321799307958,BAAI-bge-large-en,few-shot,political
macro avg,0.7820941050168038,0.7363321799307958,0.7251869873571388,2890.0,BAAI-bge-large-en,few-shot,political
weighted avg,0.7820941050168038,0.7363321799307958,0.7251869873571388,2890.0,BAAI-bge-large-en,few-shot,political
apolitical,0.703971119133574,0.13448275862068965,0.22582513028372903,1450.0,BAAI-bge-large-en,zero-shot,political
political,0.521540221120854,0.9434482758620689,0.6717407316474344,1450.0,BAAI-bge-large-en,zero-shot,political
accuracy,0.5389655172413793,0.5389655172413793,0.5389655172413793,0.5389655172413793,BAAI-bge-large-en,zero-shot,political
macro avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
weighted avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
exemplar,0.2638064810588772,0.7487046632124352,0.39014512318596023,772.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
not an exemplar,0.7263751763046544,0.24201127819548873,0.3630595699682764,2128.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
accuracy,0.37689655172413794,0.37689655172413794,0.37689655172413794,0.37689655172413794,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
macro avg,0.4950908286817658,0.495357970703962,0.37660234657711833,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
weighted avg,0.6032361995012958,0.37689655172413794,0.3702699310317425,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
apolitical,0.7033613445378152,0.5792387543252595,0.6352941176470589,1445.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
political,0.6423529411764706,0.7557093425605537,0.6944356120826709,1445.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
accuracy,0.6674740484429066,0.6674740484429066,0.6674740484429066,0.6674740484429066,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
macro avg,0.6728571428571428,0.6674740484429066,0.664864864864865,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
weighted avg,0.6728571428571429,0.6674740484429066,0.664864864864865,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
apolitical,0.8083875632682574,0.7710344827586207,0.7892693258030357,1450.0,google-flan-t5-xxl,zero-shot,political
political,0.7811470006591957,0.8172413793103448,0.7987866531850353,1450.0,google-flan-t5-xxl,zero-shot,political
accuracy,0.7941379310344827,0.7941379310344827,0.7941379310344827,0.7941379310344827,google-flan-t5-xxl,zero-shot,political
macro avg,0.7947672819637266,0.7941379310344827,0.7940279894940354,2900.0,google-flan-t5-xxl,zero-shot,political
weighted avg,0.7947672819637266,0.7941379310344827,0.7940279894940356,2900.0,google-flan-t5-xxl,zero-shot,political
exemplar,0.2621276595744681,0.7979274611398963,0.3946188340807175,772.0,google-flan-t5-xxl,zero-shot,exemplar
not an exemplar,0.7163636363636363,0.18515037593984962,0.29424943988050783,2128.0,google-flan-t5-xxl,zero-shot,exemplar
accuracy,0.3482758620689655,0.3482758620689655,0.3482758620689655,0.3482758620689655,google-flan-t5-xxl,zero-shot,exemplar
macro avg,0.48924564796905223,0.49153891853987297,0.34443413698061265,2900.0,google-flan-t5-xxl,zero-shot,exemplar
weighted avg,0.5954428866804508,0.3482758620689655,0.3209684648193223,2900.0,google-flan-t5-xxl,zero-shot,exemplar
apolitical,0.7562540089801154,0.815916955017301,0.784953395472703,1445.0,stabilityai-StableBeluga-13B,few-shot,political
political,0.8001502629601803,0.7370242214532872,0.7672910662824207,1445.0,stabilityai-StableBeluga-13B,few-shot,political
accuracy,0.7764705882352941,0.7764705882352941,0.7764705882352941,0.7764705882352941,stabilityai-StableBeluga-13B,few-shot,political
macro avg,0.7782021359701479,0.776470588235294,0.7761222308775619,2890.0,stabilityai-StableBeluga-13B,few-shot,political
weighted avg,0.7782021359701479,0.7764705882352941,0.7761222308775618,2890.0,stabilityai-StableBeluga-13B,few-shot,political
general complaint,0.7910447761194029,0.5638297872340425,0.6583850931677019,94.0,google-flan-t5-xxl,zero-shot,topic
personal complaint,0.8,0.5,0.6153846153846154,16.0,google-flan-t5-xxl,zero-shot,topic
platform policies,0.6607142857142857,0.7254901960784313,0.6915887850467289,51.0,google-flan-t5-xxl,zero-shot,topic
section 230,0.9742765273311897,0.9967105263157895,0.9853658536585366,304.0,google-flan-t5-xxl,zero-shot,topic
trump ban,0.8770053475935828,1.0,0.9344729344729344,164.0,google-flan-t5-xxl,zero-shot,topic
twitter support,1.0,0.6666666666666666,0.8,6.0,google-flan-t5-xxl,zero-shot,topic
accuracy,0.8960629921259843,0.8960629921259843,0.8960629921259843,0.8960629921259843,google-flan-t5-xxl,zero-shot,topic
macro avg,0.8505068227930769,0.742116196049155,0.7808662136217529,635.0,google-flan-t5-xxl,zero-shot,topic
weighted avg,0.8926985493554042,0.8960629921259843,0.8891498604835549,635.0,google-flan-t5-xxl,zero-shot,topic
constitutionality and jurisprudency,0.17647058823529413,0.6,0.2727272727272727,20.0,google-flan-t5-xxl,zero-shot,frame
economic,0.14285714285714285,0.5,0.22222222222222224,2.0,google-flan-t5-xxl,zero-shot,frame
external regulation and reputation,0.0,0.0,0.0,1.0,google-flan-t5-xxl,zero-shot,frame
fairness and equality,0.7,0.1794871794871795,0.2857142857142857,39.0,google-flan-t5-xxl,zero-shot,frame
"law and order, crime and justice frames",0.08450704225352113,0.5,0.14457831325301204,12.0,google-flan-t5-xxl,zero-shot,frame
morality,0.08823529411764706,0.5,0.15,6.0,google-flan-t5-xxl,zero-shot,frame
other,0.01098901098901099,0.25,0.021052631578947368,4.0,google-flan-t5-xxl,zero-shot,frame
policy prescription and evaluation,0.9047619047619048,0.08878504672897196,0.16170212765957448,214.0,google-flan-t5-xxl,zero-shot,frame
political,0.5454545454545454,0.3,0.3870967741935483,20.0,google-flan-t5-xxl,zero-shot,frame
security and defense frames,0.0,0.0,0.0,4.0,google-flan-t5-xxl,zero-shot,frame
accuracy,0.17080745341614906,0.17080745341614906,0.17080745341614906,0.17080745341614906,google-flan-t5-xxl,zero-shot,frame
macro avg,0.2653275528669066,0.29182722262161515,0.16450936273488628,322.0,google-flan-t5-xxl,zero-shot,frame
weighted avg,0.736741356814481,0.17080745341614906,0.19287946624291577,322.0,google-flan-t5-xxl,zero-shot,frame
apolitical,0.7013311148086523,0.5813793103448276,0.6357466063348417,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
political,0.6425206124852768,0.7524137931034482,0.6931385006353241,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
accuracy,0.666896551724138,0.666896551724138,0.666896551724138,0.666896551724138,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
macro avg,0.6719258636469645,0.6668965517241379,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
weighted avg,0.6719258636469646,0.666896551724138,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
