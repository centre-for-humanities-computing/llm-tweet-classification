,precision,recall,f1-score,support,models,tasks,columns
apolitical,0.8617594254937163,0.6620689655172414,0.748829953198128,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
political,0.7256438969764838,0.8937931034482759,0.8009888751545117,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
accuracy,0.7779310344827586,0.7779310344827586,0.7779310344827586,0.7779310344827586,stabilityai-StableBeluga-13B,zero-shot,political
macro avg,0.7937016612351,0.7779310344827586,0.7749094141763198,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
weighted avg,0.7937016612351,0.7779310344827586,0.7749094141763198,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
apolitical,0.7641693811074919,0.8117647058823529,0.7872483221476511,1445.0,google-flan-t5-xxl,few-shot,political
political,0.7992619926199263,0.7494809688581315,0.7735714285714286,1445.0,google-flan-t5-xxl,few-shot,political
accuracy,0.7806228373702422,0.7806228373702422,0.7806228373702422,0.7806228373702422,google-flan-t5-xxl,few-shot,political
macro avg,0.7817156868637091,0.7806228373702422,0.7804098753595399,2890.0,google-flan-t5-xxl,few-shot,political
weighted avg,0.7817156868637091,0.7806228373702422,0.7804098753595398,2890.0,google-flan-t5-xxl,few-shot,political
exemplar,0.4818941504178273,0.4481865284974093,0.46442953020134226,772.0,google-flan-t5-xxl,zero-shot,exemplar
not an exemplar,0.8047662694775435,0.825187969924812,0.8148491879350348,2128.0,google-flan-t5-xxl,zero-shot,exemplar
accuracy,0.7248275862068966,0.7248275862068966,0.7248275862068966,0.7248275862068966,google-flan-t5-xxl,zero-shot,exemplar
macro avg,0.6433302099476854,0.6366872492111106,0.6396393590681886,2900.0,google-flan-t5-xxl,zero-shot,exemplar
weighted avg,0.7188154846795776,0.7248275862068966,0.7215650583590312,2900.0,google-flan-t5-xxl,zero-shot,exemplar
exemplar,0.3261802575107296,0.1981747066492829,0.24655312246553124,767.0,stabilityai-StableBeluga-13B,few-shot,exemplar
not an exemplar,0.7462871287128713,0.8520960904380593,0.7956894655817023,2123.0,stabilityai-StableBeluga-13B,few-shot,exemplar
accuracy,0.6785467128027681,0.6785467128027681,0.6785467128027681,0.6785467128027681,stabilityai-StableBeluga-13B,few-shot,exemplar
macro avg,0.5362336931118005,0.5251353985436711,0.5211212940236167,2890.0,stabilityai-StableBeluga-13B,few-shot,exemplar
weighted avg,0.6347916372900192,0.6785467128027681,0.6499498201941234,2890.0,stabilityai-StableBeluga-13B,few-shot,exemplar
exemplar,0.396969696969697,0.5090673575129534,0.4460839954597049,772.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
not an exemplar,0.8015706806282723,0.7194548872180451,0.7582961862308074,2128.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
accuracy,0.663448275862069,0.663448275862069,0.663448275862069,0.663448275862069,stabilityai-StableBeluga-13B,zero-shot,exemplar
macro avg,0.5992701887989846,0.6142611223654992,0.6021900908452562,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
weighted avg,0.6938631084267481,0.663448275862069,0.6751831478600173,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
apolitical,0.49226441631504925,0.4827586206896552,0.48746518105849584,1450.0,gpt-4,zero-shot,political
political,0.4925575101488498,0.5020689655172413,0.4972677595628415,1450.0,gpt-4,zero-shot,political
accuracy,0.4924137931034483,0.4924137931034483,0.4924137931034483,0.4924137931034483,gpt-4,zero-shot,political
macro avg,0.49241096323194955,0.49241379310344824,0.4923664703106687,2900.0,gpt-4,zero-shot,political
weighted avg,0.49241096323194955,0.4924137931034483,0.49236647031066866,2900.0,gpt-4,zero-shot,political
apolitical,0.7416666666666667,0.8593103448275862,0.7961661341853035,1450.0,google-flan-t5-xxl,zero-shot,political
political,0.8327868852459016,0.7006896551724138,0.7610486891385768,1450.0,google-flan-t5-xxl,zero-shot,political
accuracy,0.78,0.78,0.78,0.78,google-flan-t5-xxl,zero-shot,political
macro avg,0.7872267759562841,0.78,0.7786074116619401,2900.0,google-flan-t5-xxl,zero-shot,political
weighted avg,0.7872267759562842,0.78,0.7786074116619401,2900.0,google-flan-t5-xxl,zero-shot,political
