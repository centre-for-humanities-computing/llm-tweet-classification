,precision,recall,f1-score,support,models,tasks,columns
exemplar,0.24244152880775813,0.5505181347150259,0.33663366336633666,772.0,google-flan-t5-xxl,zero-shot,exemplar
nonexemplar,0.6974716652136007,0.37593984962406013,0.4885496183206107,2128.0,google-flan-t5-xxl,zero-shot,exemplar
accuracy,0.4224137931034483,0.4224137931034483,0.4224137931034483,0.4224137931034483,google-flan-t5-xxl,zero-shot,exemplar
macro avg,0.46995659701067943,0.463228992169543,0.41259164084347366,2900.0,google-flan-t5-xxl,zero-shot,exemplar
weighted avg,0.5763395047634936,0.4224137931034483,0.4481085434155419,2900.0,google-flan-t5-xxl,zero-shot,exemplar
apolitical,0.703971119133574,0.13448275862068965,0.22582513028372903,1450.0,BAAI-bge-large-en,zero-shot,political
political,0.521540221120854,0.9434482758620689,0.6717407316474344,1450.0,BAAI-bge-large-en,zero-shot,political
accuracy,0.5389655172413793,0.5389655172413793,0.5389655172413793,0.5389655172413793,BAAI-bge-large-en,zero-shot,political
macro avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
weighted avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
exemplar,0.24897330595482547,0.6282383419689119,0.35661764705882354,772.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
nonexemplar,0.6985294117647058,0.3125,0.43181818181818177,2128.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
accuracy,0.39655172413793105,0.39655172413793105,0.39655172413793105,0.39655172413793105,stabilityai-StableBeluga-13B,zero-shot,exemplar
macro avg,0.47375135885976566,0.47036917098445596,0.3942179144385026,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
weighted avg,0.5788544760111791,0.39655172413793105,0.4117992808408629,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
apolitical,0.6295585412667947,0.9048275862068965,0.7425014148273911,1450.0,BAAI-bge-large-en,few-shot,political
political,0.8308823529411765,0.4675862068965517,0.5984112974404237,1450.0,BAAI-bge-large-en,few-shot,political
accuracy,0.6862068965517242,0.6862068965517242,0.6862068965517242,0.6862068965517242,BAAI-bge-large-en,few-shot,political
macro avg,0.7302204471039856,0.6862068965517241,0.6704563561339074,2900.0,BAAI-bge-large-en,few-shot,political
weighted avg,0.7302204471039856,0.6862068965517242,0.6704563561339073,2900.0,BAAI-bge-large-en,few-shot,political
apolitical,0.824357912178956,0.6862068965517242,0.7489649981181784,1450.0,gpt-3.5-turbo,zero-shot,political
political,0.7312463083284111,0.8537931034482759,0.7877823735284759,1450.0,gpt-3.5-turbo,zero-shot,political
accuracy,0.77,0.77,0.77,0.77,gpt-3.5-turbo,zero-shot,political
macro avg,0.7778021102536836,0.77,0.7683736858233272,2900.0,gpt-3.5-turbo,zero-shot,political
weighted avg,0.7778021102536836,0.77,0.7683736858233271,2900.0,gpt-3.5-turbo,zero-shot,political
exemplar,0.2890625,0.7668393782383419,0.41985815602836873,772.0,gpt-4,few-shot,exemplar
nonexemplar,0.7887323943661971,0.3157894736842105,0.45100671140939597,2128.0,gpt-4,few-shot,exemplar
accuracy,0.43586206896551727,0.43586206896551727,0.43586206896551727,0.43586206896551727,gpt-4,few-shot,exemplar
macro avg,0.5388974471830985,0.5413144259612762,0.43543243371888235,2900.0,gpt-4,few-shot,exemplar
weighted avg,0.655716822486644,0.43586206896551727,0.4427147511493432,2900.0,gpt-4,few-shot,exemplar
apolitical,0.6901805869074492,0.8434482758620689,0.7591558038485413,1450.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
political,0.7987588652482269,0.6213793103448276,0.6989914662529093,1450.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
accuracy,0.7324137931034482,0.7324137931034482,0.7324137931034482,0.7324137931034482,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
macro avg,0.7444697260778381,0.7324137931034482,0.7290736350507253,2900.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
weighted avg,0.744469726077838,0.7324137931034482,0.7290736350507252,2900.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
exemplar,0.40192704748795594,0.7564766839378239,0.5249438202247191,772.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
nonexemplar,0.8700760193503801,0.5916353383458647,0.7043356643356644,2128.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
accuracy,0.6355172413793103,0.6355172413793103,0.6355172413793103,0.6355172413793103,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
macro avg,0.636001533419168,0.6740560111418443,0.6146397422801917,2900.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
weighted avg,0.7454515344270038,0.6355172413793103,0.656580318248199,2900.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
exemplar,0.2571428571428571,0.034974093264248704,0.06157354618015963,772.0,gpt-4,zero-shot,exemplar
nonexemplar,0.7334525939177102,0.9633458646616542,0.8328255128986389,2128.0,gpt-4,zero-shot,exemplar
accuracy,0.7162068965517241,0.7162068965517241,0.7162068965517241,0.7162068965517241,gpt-4,zero-shot,exemplar
macro avg,0.4952977255302837,0.49915997896295144,0.4471995295393993,2900.0,gpt-4,zero-shot,exemplar
weighted avg,0.606655657093508,0.7162068965517241,0.627512920379099,2900.0,gpt-4,zero-shot,exemplar
exemplar,0.272887323943662,0.8031088082901554,0.40735873850197113,772.0,BAAI-bge-large-en,zero-shot,exemplar
nonexemplar,0.7579617834394905,0.2236842105263158,0.3454281567489115,2128.0,BAAI-bge-large-en,zero-shot,exemplar
accuracy,0.3779310344827586,0.3779310344827586,0.3779310344827586,0.3779310344827586,BAAI-bge-large-en,zero-shot,exemplar
macro avg,0.5154245536915762,0.5133965094082356,0.3763934476254413,2900.0,BAAI-bge-large-en,zero-shot,exemplar
weighted avg,0.628831616980601,0.3779310344827586,0.36191450471903636,2900.0,BAAI-bge-large-en,zero-shot,exemplar
exemplar,0.2695984703632887,0.5479274611398963,0.36138402392140107,772.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
nonexemplar,0.7377911344853494,0.46146616541353386,0.5677941601618965,2128.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
accuracy,0.4844827586206897,0.4844827586206897,0.4844827586206897,0.4844827586206897,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
macro avg,0.5036948024243191,0.5046968132767151,0.4645890920416488,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
weighted avg,0.6131550183811318,0.4844827586206897,0.5128463583764956,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
apolitical,0.8926829268292683,0.7572413793103449,0.8194029850746269,1450.0,gpt-4,few-shot,political
political,0.7892215568862275,0.9089655172413793,0.8448717948717949,1450.0,gpt-4,few-shot,political
accuracy,0.833103448275862,0.833103448275862,0.833103448275862,0.833103448275862,gpt-4,few-shot,political
macro avg,0.840952241857748,0.8331034482758621,0.832137389973211,2900.0,gpt-4,few-shot,political
weighted avg,0.840952241857748,0.833103448275862,0.832137389973211,2900.0,gpt-4,few-shot,political
exemplar,0.30180806675938804,0.2810880829015544,0.2910798122065728,772.0,gpt-3.5-turbo,zero-shot,exemplar
nonexemplar,0.7455295735900963,0.7640977443609023,0.754699466233465,2128.0,gpt-3.5-turbo,zero-shot,exemplar
accuracy,0.6355172413793103,0.6355172413793103,0.6355172413793103,0.6355172413793103,gpt-3.5-turbo,zero-shot,exemplar
macro avg,0.5236688201747421,0.5225929136312284,0.5228896392200189,2900.0,gpt-3.5-turbo,zero-shot,exemplar
weighted avg,0.6274078483234388,0.6355172413793103,0.6312807169545819,2900.0,gpt-3.5-turbo,zero-shot,exemplar
exemplar,0.2701838529176659,0.8756476683937824,0.4129505192425168,772.0,gpt-3.5-turbo,few-shot,exemplar
nonexemplar,0.7587939698492462,0.14191729323308272,0.23911322248614414,2128.0,gpt-3.5-turbo,few-shot,exemplar
accuracy,0.3372413793103448,0.3372413793103448,0.3372413793103448,0.3372413793103448,gpt-3.5-turbo,few-shot,exemplar
macro avg,0.5144889113834561,0.5087824808134326,0.3260318708643305,2900.0,gpt-3.5-turbo,few-shot,exemplar
weighted avg,0.6287225869971151,0.3372413793103448,0.2853899097605992,2900.0,gpt-3.5-turbo,few-shot,exemplar
exemplar,0.291354663036079,0.5544041450777202,0.38197233377956263,772.0,stabilityai-StableBeluga-13B,few-shot,exemplar
nonexemplar,0.7596086652690426,0.5108082706766918,0.6108457431862884,2128.0,stabilityai-StableBeluga-13B,few-shot,exemplar
accuracy,0.5224137931034483,0.5224137931034483,0.5224137931034483,0.5224137931034483,stabilityai-StableBeluga-13B,few-shot,exemplar
macro avg,0.5254816641525608,0.532606207877206,0.4964090384829255,2900.0,stabilityai-StableBeluga-13B,few-shot,exemplar
weighted avg,0.6349562205366812,0.5224137931034483,0.5499180631649117,2900.0,stabilityai-StableBeluga-13B,few-shot,exemplar
apolitical,0.8156797331109258,0.6744827586206896,0.7383918459796149,1450.0,stabilityai-StableBeluga-13B,few-shot,political
political,0.7225161669606114,0.8475862068965517,0.780069819105046,1450.0,stabilityai-StableBeluga-13B,few-shot,political
accuracy,0.7610344827586207,0.7610344827586207,0.7610344827586207,0.7610344827586207,stabilityai-StableBeluga-13B,few-shot,political
macro avg,0.7690979500357686,0.7610344827586206,0.7592308325423305,2900.0,stabilityai-StableBeluga-13B,few-shot,political
weighted avg,0.7690979500357685,0.7610344827586207,0.7592308325423305,2900.0,stabilityai-StableBeluga-13B,few-shot,political
apolitical,0.8951048951048951,0.5296551724137931,0.6655112651646448,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
political,0.6660137120470128,0.9379310344827586,0.7789232531500573,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
accuracy,0.7337931034482759,0.7337931034482759,0.7337931034482759,0.7337931034482759,stabilityai-StableBeluga-13B,zero-shot,political
macro avg,0.7805593035759539,0.7337931034482759,0.722217259157351,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
weighted avg,0.7805593035759539,0.7337931034482759,0.7222172591573509,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
exemplar,0.384151593453919,0.5777202072538861,0.46145887221934817,772.0,BAAI-bge-large-en,few-shot,exemplar
nonexemplar,0.8125359401955147,0.6640037593984962,0.7307990690457719,2128.0,BAAI-bge-large-en,few-shot,exemplar
accuracy,0.6410344827586207,0.6410344827586207,0.6410344827586207,0.6410344827586207,BAAI-bge-large-en,few-shot,exemplar
macro avg,0.5983437668247169,0.6208619833261911,0.59612897063256,2900.0,BAAI-bge-large-en,few-shot,exemplar
weighted avg,0.6984970727180968,0.6410344827586207,0.6590988511319791,2900.0,BAAI-bge-large-en,few-shot,exemplar
apolitical,0.8083875632682574,0.7710344827586207,0.7892693258030357,1450.0,google-flan-t5-xxl,zero-shot,political
political,0.7811470006591957,0.8172413793103448,0.7987866531850353,1450.0,google-flan-t5-xxl,zero-shot,political
accuracy,0.7941379310344827,0.7941379310344827,0.7941379310344827,0.7941379310344827,google-flan-t5-xxl,zero-shot,political
macro avg,0.7947672819637266,0.7941379310344827,0.7940279894940354,2900.0,google-flan-t5-xxl,zero-shot,political
weighted avg,0.7947672819637266,0.7941379310344827,0.7940279894940356,2900.0,google-flan-t5-xxl,zero-shot,political
apolitical,0.8615771812080537,0.7082758620689655,0.777441332323997,1450.0,gpt-4,zero-shot,political
political,0.7523419203747073,0.8862068965517241,0.8138062064597846,1450.0,gpt-4,zero-shot,political
accuracy,0.7972413793103448,0.7972413793103448,0.7972413793103448,0.7972413793103448,gpt-4,zero-shot,political
macro avg,0.8069595507913805,0.7972413793103448,0.7956237693918908,2900.0,gpt-4,zero-shot,political
weighted avg,0.8069595507913805,0.7972413793103448,0.795623769391891,2900.0,gpt-4,zero-shot,political
apolitical,0.7669027688345138,0.8213793103448276,0.7932067932067932,1450.0,google-flan-t5-xxl,few-shot,political
political,0.807720861172977,0.7503448275862069,0.7779764032892386,1450.0,google-flan-t5-xxl,few-shot,political
accuracy,0.7858620689655172,0.7858620689655172,0.7858620689655172,0.7858620689655172,google-flan-t5-xxl,few-shot,political
macro avg,0.7873118150037455,0.7858620689655172,0.7855915982480159,2900.0,google-flan-t5-xxl,few-shot,political
weighted avg,0.7873118150037455,0.7858620689655172,0.7855915982480158,2900.0,google-flan-t5-xxl,few-shot,political
apolitical,0.8972067039106145,0.5537931034482758,0.684861407249467,1450.0,gpt-3.5-turbo,few-shot,political
political,0.6773067331670823,0.9365517241379311,0.7861070911722142,1450.0,gpt-3.5-turbo,few-shot,political
accuracy,0.7451724137931034,0.7451724137931034,0.7451724137931034,0.7451724137931034,gpt-3.5-turbo,few-shot,political
macro avg,0.7872567185388484,0.7451724137931035,0.7354842492108407,2900.0,gpt-3.5-turbo,few-shot,political
weighted avg,0.7872567185388485,0.7451724137931034,0.7354842492108407,2900.0,gpt-3.5-turbo,few-shot,political
exemplar,0.2784184514003295,0.2189119170984456,0.24510514865844818,772.0,google-flan-t5-xxl,few-shot,exemplar
nonexemplar,0.737025730484082,0.7941729323308271,0.7645329111060847,2128.0,google-flan-t5-xxl,few-shot,exemplar
accuracy,0.6410344827586207,0.6410344827586207,0.6410344827586207,0.6410344827586207,google-flan-t5-xxl,few-shot,exemplar
macro avg,0.5077220909422058,0.5065424247146364,0.5048190298822665,2900.0,google-flan-t5-xxl,few-shot,exemplar
weighted avg,0.6149413099831659,0.6410344827586207,0.6262576584820932,2900.0,google-flan-t5-xxl,few-shot,exemplar
apolitical,0.7013311148086523,0.5813793103448276,0.6357466063348417,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
political,0.6425206124852768,0.7524137931034482,0.6931385006353241,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
accuracy,0.666896551724138,0.666896551724138,0.666896551724138,0.666896551724138,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
macro avg,0.6719258636469645,0.6668965517241379,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
weighted avg,0.6719258636469646,0.666896551724138,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
