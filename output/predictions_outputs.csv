,precision,recall,f1-score,support,models,tasks,columns
exemplar,0.25380931649978233,0.7601043024771839,0.38054830287206265,767.0,google-flan-t5-xxl,few-shot,exemplar
not an exemplar,0.6897133220910624,0.19265190767781443,0.3011782032400589,2123.0,google-flan-t5-xxl,few-shot,exemplar
accuracy,0.34325259515570933,0.34325259515570933,0.34325259515570933,0.34325259515570933,google-flan-t5-xxl,few-shot,exemplar
macro avg,0.47176131929542237,0.4763781050774991,0.3408632530560608,2890.0,google-flan-t5-xxl,few-shot,exemplar
weighted avg,0.5740253039981518,0.34325259515570933,0.32224286290017895,2890.0,google-flan-t5-xxl,few-shot,exemplar
exemplar,0.2625139043381535,0.917098445595855,0.4081867973479389,772.0,BAAI-bge-large-en,zero-shot,exemplar
not an exemplar,0.6847290640394089,0.06531954887218046,0.11926211926211926,2128.0,BAAI-bge-large-en,zero-shot,exemplar
accuracy,0.2920689655172414,0.2920689655172414,0.2920689655172414,0.2920689655172414,BAAI-bge-large-en,zero-shot,exemplar
macro avg,0.47362148418878125,0.49120899723401773,0.26372445830502905,2900.0,BAAI-bge-large-en,zero-shot,exemplar
weighted avg,0.5723324766982472,0.2920689655172414,0.19617586115255123,2900.0,BAAI-bge-large-en,zero-shot,exemplar
apolitical,0.8951048951048951,0.5296551724137931,0.6655112651646448,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
political,0.6660137120470128,0.9379310344827586,0.7789232531500573,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
accuracy,0.7337931034482759,0.7337931034482759,0.7337931034482759,0.7337931034482759,stabilityai-StableBeluga-13B,zero-shot,political
macro avg,0.7805593035759539,0.7337931034482759,0.722217259157351,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
weighted avg,0.7805593035759539,0.7337931034482759,0.7222172591573509,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
exemplar,0.38248502994011974,0.666232073011734,0.48597242035187826,767.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
not an exemplar,0.8352638352638353,0.6113989637305699,0.7060103345118304,2123.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
accuracy,0.6259515570934256,0.6259515570934256,0.6259515570934256,0.6259515570934256,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
macro avg,0.6088744326019775,0.6388155183711519,0.5959913774318544,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
weighted avg,0.7150972803561225,0.6259515570934256,0.6476127289198984,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
exemplar,0.42857142857142855,0.019430051813471502,0.03717472118959107,772.0,gpt-3.5-turbo,zero-shot,exemplar
not an exemplar,0.7357766143106457,0.9906015037593985,0.8443821349889845,2128.0,gpt-3.5-turbo,zero-shot,exemplar
accuracy,0.7320689655172414,0.7320689655172414,0.7320689655172414,0.7320689655172414,gpt-3.5-turbo,zero-shot,exemplar
macro avg,0.5821740214410371,0.505015777786435,0.4407784280892878,2900.0,gpt-3.5-turbo,zero-shot,exemplar
weighted avg,0.6539964752104127,0.7320689655172414,0.6294979544879046,2900.0,gpt-3.5-turbo,zero-shot,exemplar
exemplar,0.3826879271070615,0.4380704041720991,0.40851063829787226,767.0,BAAI-bge-large-en,few-shot,exemplar
not an exemplar,0.7857852882703777,0.7447008949599623,0.7646916565900845,2123.0,BAAI-bge-large-en,few-shot,exemplar
accuracy,0.6633217993079584,0.6633217993079584,0.6633217993079584,0.6633217993079584,BAAI-bge-large-en,few-shot,exemplar
macro avg,0.5842366076887197,0.5913856495660307,0.5866011474439784,2890.0,BAAI-bge-large-en,few-shot,exemplar
weighted avg,0.6788040854979682,0.6633217993079584,0.6701619538114939,2890.0,BAAI-bge-large-en,few-shot,exemplar
apolitical,0.6684755796743956,0.9377162629757786,0.7805299539170507,1445.0,BAAI-bge-large-en,few-shot,political
political,0.895712630359212,0.5349480968858131,0.669844020797227,1445.0,BAAI-bge-large-en,few-shot,political
accuracy,0.7363321799307958,0.7363321799307958,0.7363321799307958,0.7363321799307958,BAAI-bge-large-en,few-shot,political
macro avg,0.7820941050168038,0.7363321799307958,0.7251869873571388,2890.0,BAAI-bge-large-en,few-shot,political
weighted avg,0.7820941050168038,0.7363321799307958,0.7251869873571388,2890.0,BAAI-bge-large-en,few-shot,political
exemplar,0.3594306049822064,0.6516129032258065,0.463302752293578,155.0,gpt-4,few-shot,exemplar
not an exemplar,0.8193979933110368,0.5764705882352941,0.6767955801104972,425.0,gpt-4,few-shot,exemplar
accuracy,0.596551724137931,0.596551724137931,0.596551724137931,0.596551724137931,gpt-4,few-shot,exemplar
macro avg,0.5894142991466216,0.6140417457305503,0.5700491662020376,580.0,gpt-4,few-shot,exemplar
weighted avg,0.6964756740162632,0.596551724137931,0.6197414623318378,580.0,gpt-4,few-shot,exemplar
apolitical,0.703971119133574,0.13448275862068965,0.22582513028372903,1450.0,BAAI-bge-large-en,zero-shot,political
political,0.521540221120854,0.9434482758620689,0.6717407316474344,1450.0,BAAI-bge-large-en,zero-shot,political
accuracy,0.5389655172413793,0.5389655172413793,0.5389655172413793,0.5389655172413793,BAAI-bge-large-en,zero-shot,political
macro avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
weighted avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
exemplar,0.2638064810588772,0.7487046632124352,0.39014512318596023,772.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
not an exemplar,0.7263751763046544,0.24201127819548873,0.3630595699682764,2128.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
accuracy,0.37689655172413794,0.37689655172413794,0.37689655172413794,0.37689655172413794,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
macro avg,0.4950908286817658,0.495357970703962,0.37660234657711833,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
weighted avg,0.6032361995012958,0.37689655172413794,0.3702699310317425,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
exemplar,0.2429742388758782,0.5375647668393783,0.33467741935483875,772.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
not an exemplar,0.700503355704698,0.3923872180451128,0.503012048192771,2128.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
accuracy,0.43103448275862066,0.43103448275862066,0.43103448275862066,0.43103448275862066,stabilityai-StableBeluga-13B,zero-shot,exemplar
macro avg,0.4717387972902881,0.4649759924422455,0.4188447337738049,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
weighted avg,0.5787059494316467,0.43103448275862066,0.4582002090676387,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
exemplar,0.21830985915492956,0.08031088082901554,0.11742424242424242,772.0,gpt-4,zero-shot,exemplar
not an exemplar,0.7285932721712538,0.8956766917293233,0.8035413153456998,2128.0,gpt-4,zero-shot,exemplar
accuracy,0.6786206896551724,0.6786206896551724,0.6786206896551724,0.6786206896551724,gpt-4,zero-shot,exemplar
macro avg,0.47345156566309166,0.4879937862791694,0.46048277888497113,2900.0,gpt-4,zero-shot,exemplar
weighted avg,0.5927523084303564,0.6786206896551724,0.6208922186921257,2900.0,gpt-4,zero-shot,exemplar
apolitical,0.8273615635179153,0.8438538205980066,0.8355263157894737,301.0,gpt-3.5-turbo,few-shot,political
political,0.8278388278388278,0.8100358422939068,0.8188405797101448,279.0,gpt-3.5-turbo,few-shot,political
accuracy,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,gpt-3.5-turbo,few-shot,political
macro avg,0.8276001956783716,0.8269448314459567,0.8271834477498092,580.0,gpt-3.5-turbo,few-shot,political
weighted avg,0.8275911441136647,0.8275862068965517,0.8274999013651069,580.0,gpt-3.5-turbo,few-shot,political
apolitical,0.7033613445378152,0.5792387543252595,0.6352941176470589,1445.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
political,0.6423529411764706,0.7557093425605537,0.6944356120826709,1445.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
accuracy,0.6674740484429066,0.6674740484429066,0.6674740484429066,0.6674740484429066,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
macro avg,0.6728571428571428,0.6674740484429066,0.664864864864865,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
weighted avg,0.6728571428571429,0.6674740484429066,0.664864864864865,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
apolitical,0.824357912178956,0.6862068965517242,0.7489649981181784,1450.0,gpt-3.5-turbo,zero-shot,political
political,0.7312463083284111,0.8537931034482759,0.7877823735284759,1450.0,gpt-3.5-turbo,zero-shot,political
accuracy,0.77,0.77,0.77,0.77,gpt-3.5-turbo,zero-shot,political
macro avg,0.7778021102536836,0.77,0.7683736858233272,2900.0,gpt-3.5-turbo,zero-shot,political
weighted avg,0.7778021102536836,0.77,0.7683736858233271,2900.0,gpt-3.5-turbo,zero-shot,political
exemplar,0.3261802575107296,0.1981747066492829,0.24655312246553124,767.0,stabilityai-StableBeluga-13B,few-shot,exemplar
not an exemplar,0.7462871287128713,0.8520960904380593,0.7956894655817023,2123.0,stabilityai-StableBeluga-13B,few-shot,exemplar
accuracy,0.6785467128027681,0.6785467128027681,0.6785467128027681,0.6785467128027681,stabilityai-StableBeluga-13B,few-shot,exemplar
macro avg,0.5362336931118005,0.5251353985436711,0.5211212940236167,2890.0,stabilityai-StableBeluga-13B,few-shot,exemplar
weighted avg,0.6347916372900192,0.6785467128027681,0.6499498201941234,2890.0,stabilityai-StableBeluga-13B,few-shot,exemplar
apolitical,0.8083875632682574,0.7710344827586207,0.7892693258030357,1450.0,google-flan-t5-xxl,zero-shot,political
political,0.7811470006591957,0.8172413793103448,0.7987866531850353,1450.0,google-flan-t5-xxl,zero-shot,political
accuracy,0.7941379310344827,0.7941379310344827,0.7941379310344827,0.7941379310344827,google-flan-t5-xxl,zero-shot,political
macro avg,0.7947672819637266,0.7941379310344827,0.7940279894940354,2900.0,google-flan-t5-xxl,zero-shot,political
weighted avg,0.7947672819637266,0.7941379310344827,0.7940279894940356,2900.0,google-flan-t5-xxl,zero-shot,political
apolitical,0.8615771812080537,0.7082758620689655,0.777441332323997,1450.0,gpt-4,zero-shot,political
political,0.7523419203747073,0.8862068965517241,0.8138062064597846,1450.0,gpt-4,zero-shot,political
accuracy,0.7972413793103448,0.7972413793103448,0.7972413793103448,0.7972413793103448,gpt-4,zero-shot,political
macro avg,0.8069595507913805,0.7972413793103448,0.7956237693918908,2900.0,gpt-4,zero-shot,political
weighted avg,0.8069595507913805,0.7972413793103448,0.795623769391891,2900.0,gpt-4,zero-shot,political
exemplar,0.2621276595744681,0.7979274611398963,0.3946188340807175,772.0,google-flan-t5-xxl,zero-shot,exemplar
not an exemplar,0.7163636363636363,0.18515037593984962,0.29424943988050783,2128.0,google-flan-t5-xxl,zero-shot,exemplar
accuracy,0.3482758620689655,0.3482758620689655,0.3482758620689655,0.3482758620689655,google-flan-t5-xxl,zero-shot,exemplar
macro avg,0.48924564796905223,0.49153891853987297,0.34443413698061265,2900.0,google-flan-t5-xxl,zero-shot,exemplar
weighted avg,0.5954428866804508,0.3482758620689655,0.3209684648193223,2900.0,google-flan-t5-xxl,zero-shot,exemplar
apolitical,0.7562540089801154,0.815916955017301,0.784953395472703,1445.0,stabilityai-StableBeluga-13B,few-shot,political
political,0.8001502629601803,0.7370242214532872,0.7672910662824207,1445.0,stabilityai-StableBeluga-13B,few-shot,political
accuracy,0.7764705882352941,0.7764705882352941,0.7764705882352941,0.7764705882352941,stabilityai-StableBeluga-13B,few-shot,political
macro avg,0.7782021359701479,0.776470588235294,0.7761222308775619,2890.0,stabilityai-StableBeluga-13B,few-shot,political
weighted avg,0.7782021359701479,0.7764705882352941,0.7761222308775618,2890.0,stabilityai-StableBeluga-13B,few-shot,political
exemplar,0.3,0.3409090909090909,0.3191489361702128,132.0,gpt-3.5-turbo,few-shot,exemplar
not an exemplar,0.7976744186046512,0.765625,0.7813211845102506,448.0,gpt-3.5-turbo,few-shot,exemplar
accuracy,0.6689655172413793,0.6689655172413793,0.6689655172413793,0.6689655172413793,gpt-3.5-turbo,few-shot,exemplar
macro avg,0.5488372093023256,0.5532670454545454,0.5502350603402317,580.0,gpt-3.5-turbo,few-shot,exemplar
weighted avg,0.684410585404972,0.6689655172413793,0.6761371555776903,580.0,gpt-3.5-turbo,few-shot,exemplar
apolitical,0.7013311148086523,0.5813793103448276,0.6357466063348417,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
political,0.6425206124852768,0.7524137931034482,0.6931385006353241,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
accuracy,0.666896551724138,0.666896551724138,0.666896551724138,0.666896551724138,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
macro avg,0.6719258636469645,0.6668965517241379,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
weighted avg,0.6719258636469646,0.666896551724138,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
