,precision,recall,f1-score,support,models,tasks,columns
exemplar,0.24244152880775813,0.5505181347150259,0.33663366336633666,772.0,google-flan-t5-xxl,zero-shot,exemplar
nonexemplar,0.6974716652136007,0.37593984962406013,0.4885496183206107,2128.0,google-flan-t5-xxl,zero-shot,exemplar
accuracy,0.4224137931034483,0.4224137931034483,0.4224137931034483,0.4224137931034483,google-flan-t5-xxl,zero-shot,exemplar
macro avg,0.46995659701067943,0.463228992169543,0.41259164084347366,2900.0,google-flan-t5-xxl,zero-shot,exemplar
weighted avg,0.5763395047634936,0.4224137931034483,0.4481085434155419,2900.0,google-flan-t5-xxl,zero-shot,exemplar
apolitical,0.703971119133574,0.13448275862068965,0.22582513028372903,1450.0,BAAI-bge-large-en,zero-shot,political
political,0.521540221120854,0.9434482758620689,0.6717407316474344,1450.0,BAAI-bge-large-en,zero-shot,political
accuracy,0.5389655172413793,0.5389655172413793,0.5389655172413793,0.5389655172413793,BAAI-bge-large-en,zero-shot,political
macro avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
weighted avg,0.612755670127214,0.5389655172413793,0.44878293096558175,2900.0,BAAI-bge-large-en,zero-shot,political
exemplar,0.24897330595482547,0.6282383419689119,0.35661764705882354,772.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
nonexemplar,0.6985294117647058,0.3125,0.43181818181818177,2128.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
accuracy,0.39655172413793105,0.39655172413793105,0.39655172413793105,0.39655172413793105,stabilityai-StableBeluga-13B,zero-shot,exemplar
macro avg,0.47375135885976566,0.47036917098445596,0.3942179144385026,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
weighted avg,0.5788544760111791,0.39655172413793105,0.4117992808408629,2900.0,stabilityai-StableBeluga-13B,zero-shot,exemplar
apolitical,0.6684755796743956,0.9377162629757786,0.7805299539170507,1445.0,BAAI-bge-large-en,few-shot,political
political,0.895712630359212,0.5349480968858131,0.669844020797227,1445.0,BAAI-bge-large-en,few-shot,political
accuracy,0.7363321799307958,0.7363321799307958,0.7363321799307958,0.7363321799307958,BAAI-bge-large-en,few-shot,political
macro avg,0.7820941050168038,0.7363321799307958,0.7251869873571388,2890.0,BAAI-bge-large-en,few-shot,political
weighted avg,0.7820941050168038,0.7363321799307958,0.7251869873571388,2890.0,BAAI-bge-large-en,few-shot,political
apolitical,0.824357912178956,0.6862068965517242,0.7489649981181784,1450.0,gpt-3.5-turbo,zero-shot,political
political,0.7312463083284111,0.8537931034482759,0.7877823735284759,1450.0,gpt-3.5-turbo,zero-shot,political
accuracy,0.77,0.77,0.77,0.77,gpt-3.5-turbo,zero-shot,political
macro avg,0.7778021102536836,0.77,0.7683736858233272,2900.0,gpt-3.5-turbo,zero-shot,political
weighted avg,0.7778021102536836,0.77,0.7683736858233271,2900.0,gpt-3.5-turbo,zero-shot,political
exemplar,0.30417495029821073,0.7979139504563233,0.440446203670385,767.0,gpt-4,few-shot,exemplar
nonexemplar,0.8234624145785877,0.3405558172397551,0.48183938687104305,2123.0,gpt-4,few-shot,exemplar
accuracy,0.4619377162629758,0.4619377162629758,0.4619377162629758,0.4619377162629758,gpt-4,few-shot,exemplar
macro avg,0.5638186824383993,0.5692348838480392,0.461142795270714,2890.0,gpt-4,few-shot,exemplar
weighted avg,0.6856445996640378,0.4619377162629758,0.47085372198699293,2890.0,gpt-4,few-shot,exemplar
apolitical,0.7033613445378152,0.5792387543252595,0.6352941176470589,1445.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
political,0.6423529411764706,0.7557093425605537,0.6944356120826709,1445.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
accuracy,0.6674740484429066,0.6674740484429066,0.6674740484429066,0.6674740484429066,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
macro avg,0.6728571428571428,0.6674740484429066,0.664864864864865,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
weighted avg,0.6728571428571429,0.6674740484429066,0.664864864864865,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,political
exemplar,0.38248502994011974,0.666232073011734,0.48597242035187826,767.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
nonexemplar,0.8352638352638353,0.6113989637305699,0.7060103345118304,2123.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
accuracy,0.6259515570934256,0.6259515570934256,0.6259515570934256,0.6259515570934256,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
macro avg,0.6088744326019775,0.6388155183711519,0.5959913774318544,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
weighted avg,0.7150972803561225,0.6259515570934256,0.6476127289198984,2890.0,sentence-transformers-all-MiniLM-L6-v2,few-shot,exemplar
exemplar,0.2571428571428571,0.034974093264248704,0.06157354618015963,772.0,gpt-4,zero-shot,exemplar
nonexemplar,0.7334525939177102,0.9633458646616542,0.8328255128986389,2128.0,gpt-4,zero-shot,exemplar
accuracy,0.7162068965517241,0.7162068965517241,0.7162068965517241,0.7162068965517241,gpt-4,zero-shot,exemplar
macro avg,0.4952977255302837,0.49915997896295144,0.4471995295393993,2900.0,gpt-4,zero-shot,exemplar
weighted avg,0.606655657093508,0.7162068965517241,0.627512920379099,2900.0,gpt-4,zero-shot,exemplar
exemplar,0.272887323943662,0.8031088082901554,0.40735873850197113,772.0,BAAI-bge-large-en,zero-shot,exemplar
nonexemplar,0.7579617834394905,0.2236842105263158,0.3454281567489115,2128.0,BAAI-bge-large-en,zero-shot,exemplar
accuracy,0.3779310344827586,0.3779310344827586,0.3779310344827586,0.3779310344827586,BAAI-bge-large-en,zero-shot,exemplar
macro avg,0.5154245536915762,0.5133965094082356,0.3763934476254413,2900.0,BAAI-bge-large-en,zero-shot,exemplar
weighted avg,0.628831616980601,0.3779310344827586,0.36191450471903636,2900.0,BAAI-bge-large-en,zero-shot,exemplar
exemplar,0.2695984703632887,0.5479274611398963,0.36138402392140107,772.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
nonexemplar,0.7377911344853494,0.46146616541353386,0.5677941601618965,2128.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
accuracy,0.4844827586206897,0.4844827586206897,0.4844827586206897,0.4844827586206897,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
macro avg,0.5036948024243191,0.5046968132767151,0.4645890920416488,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
weighted avg,0.6131550183811318,0.4844827586206897,0.5128463583764956,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,exemplar
apolitical,0.7187681580476467,0.8560553633217993,0.7814276689829437,1445.0,gpt-4,few-shot,political
political,0.8220701454234388,0.6650519031141868,0.7352716143840857,1445.0,gpt-4,few-shot,political
accuracy,0.7605536332179931,0.7605536332179931,0.7605536332179931,0.7605536332179931,gpt-4,few-shot,political
macro avg,0.7704191517355428,0.7605536332179931,0.7583496416835147,2890.0,gpt-4,few-shot,political
weighted avg,0.7704191517355428,0.7605536332179931,0.7583496416835147,2890.0,gpt-4,few-shot,political
exemplar,0.30180806675938804,0.2810880829015544,0.2910798122065728,772.0,gpt-3.5-turbo,zero-shot,exemplar
nonexemplar,0.7455295735900963,0.7640977443609023,0.754699466233465,2128.0,gpt-3.5-turbo,zero-shot,exemplar
accuracy,0.6355172413793103,0.6355172413793103,0.6355172413793103,0.6355172413793103,gpt-3.5-turbo,zero-shot,exemplar
macro avg,0.5236688201747421,0.5225929136312284,0.5228896392200189,2900.0,gpt-3.5-turbo,zero-shot,exemplar
weighted avg,0.6274078483234388,0.6355172413793103,0.6312807169545819,2900.0,gpt-3.5-turbo,zero-shot,exemplar
exemplar,0.26938136256851997,0.8970013037809648,0.4143330322192111,767.0,gpt-3.5-turbo,few-shot,exemplar
nonexemplar,0.7648809523809523,0.1210551106924164,0.20902806018706793,2123.0,gpt-3.5-turbo,few-shot,exemplar
accuracy,0.32698961937716264,0.32698961937716264,0.32698961937716264,0.32698961937716264,gpt-3.5-turbo,few-shot,exemplar
macro avg,0.5171311574747361,0.5090282072366906,0.3116805462031395,2890.0,gpt-3.5-turbo,few-shot,exemplar
weighted avg,0.6333763899636043,0.32698961937716264,0.2635155735257025,2890.0,gpt-3.5-turbo,few-shot,exemplar
exemplar,0.28347996089931576,0.37809647979139505,0.32402234636871513,767.0,stabilityai-StableBeluga-13B,few-shot,exemplar
nonexemplar,0.7445099089448313,0.6547338671691003,0.6967418546365914,2123.0,stabilityai-StableBeluga-13B,few-shot,exemplar
accuracy,0.5813148788927336,0.5813148788927336,0.5813148788927336,0.5813148788927336,stabilityai-StableBeluga-13B,few-shot,exemplar
macro avg,0.5139949349220735,0.5164151734802477,0.5103821005026533,2890.0,stabilityai-StableBeluga-13B,few-shot,exemplar
weighted avg,0.622153517889153,0.5813148788927336,0.597822870954425,2890.0,stabilityai-StableBeluga-13B,few-shot,exemplar
apolitical,0.7562540089801154,0.815916955017301,0.784953395472703,1445.0,stabilityai-StableBeluga-13B,few-shot,political
political,0.8001502629601803,0.7370242214532872,0.7672910662824207,1445.0,stabilityai-StableBeluga-13B,few-shot,political
accuracy,0.7764705882352941,0.7764705882352941,0.7764705882352941,0.7764705882352941,stabilityai-StableBeluga-13B,few-shot,political
macro avg,0.7782021359701479,0.776470588235294,0.7761222308775619,2890.0,stabilityai-StableBeluga-13B,few-shot,political
weighted avg,0.7782021359701479,0.7764705882352941,0.7761222308775618,2890.0,stabilityai-StableBeluga-13B,few-shot,political
apolitical,0.8951048951048951,0.5296551724137931,0.6655112651646448,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
political,0.6660137120470128,0.9379310344827586,0.7789232531500573,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
accuracy,0.7337931034482759,0.7337931034482759,0.7337931034482759,0.7337931034482759,stabilityai-StableBeluga-13B,zero-shot,political
macro avg,0.7805593035759539,0.7337931034482759,0.722217259157351,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
weighted avg,0.7805593035759539,0.7337931034482759,0.7222172591573509,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
exemplar,0.3624047417442845,0.5580182529335072,0.4394250513347022,767.0,BAAI-bge-large-en,few-shot,exemplar
nonexemplar,0.8016383850204798,0.6453132359868111,0.7150313152400836,2123.0,BAAI-bge-large-en,few-shot,exemplar
accuracy,0.6221453287197232,0.6221453287197232,0.6221453287197232,0.6221453287197232,BAAI-bge-large-en,few-shot,exemplar
macro avg,0.5820215633823822,0.6016657444601592,0.5772281832873929,2890.0,BAAI-bge-large-en,few-shot,exemplar
weighted avg,0.6850666879987352,0.6221453287197232,0.6418859849925308,2890.0,BAAI-bge-large-en,few-shot,exemplar
apolitical,0.8083875632682574,0.7710344827586207,0.7892693258030357,1450.0,google-flan-t5-xxl,zero-shot,political
political,0.7811470006591957,0.8172413793103448,0.7987866531850353,1450.0,google-flan-t5-xxl,zero-shot,political
accuracy,0.7941379310344827,0.7941379310344827,0.7941379310344827,0.7941379310344827,google-flan-t5-xxl,zero-shot,political
macro avg,0.7947672819637266,0.7941379310344827,0.7940279894940354,2900.0,google-flan-t5-xxl,zero-shot,political
weighted avg,0.7947672819637266,0.7941379310344827,0.7940279894940356,2900.0,google-flan-t5-xxl,zero-shot,political
apolitical,0.8615771812080537,0.7082758620689655,0.777441332323997,1450.0,gpt-4,zero-shot,political
political,0.7523419203747073,0.8862068965517241,0.8138062064597846,1450.0,gpt-4,zero-shot,political
accuracy,0.7972413793103448,0.7972413793103448,0.7972413793103448,0.7972413793103448,gpt-4,zero-shot,political
macro avg,0.8069595507913805,0.7972413793103448,0.7956237693918908,2900.0,gpt-4,zero-shot,political
weighted avg,0.8069595507913805,0.7972413793103448,0.795623769391891,2900.0,gpt-4,zero-shot,political
apolitical,0.7641693811074919,0.8117647058823529,0.7872483221476511,1445.0,google-flan-t5-xxl,few-shot,political
political,0.7992619926199263,0.7494809688581315,0.7735714285714286,1445.0,google-flan-t5-xxl,few-shot,political
accuracy,0.7806228373702422,0.7806228373702422,0.7806228373702422,0.7806228373702422,google-flan-t5-xxl,few-shot,political
macro avg,0.7817156868637091,0.7806228373702422,0.7804098753595399,2890.0,google-flan-t5-xxl,few-shot,political
weighted avg,0.7817156868637091,0.7806228373702422,0.7804098753595398,2890.0,google-flan-t5-xxl,few-shot,political
apolitical,0.8273615635179153,0.8438538205980066,0.8355263157894737,301.0,gpt-3.5-turbo,few-shot,political
political,0.8278388278388278,0.8100358422939068,0.8188405797101448,279.0,gpt-3.5-turbo,few-shot,political
accuracy,0.8275862068965517,0.8275862068965517,0.8275862068965517,0.8275862068965517,gpt-3.5-turbo,few-shot,political
macro avg,0.8276001956783716,0.8269448314459567,0.8271834477498092,580.0,gpt-3.5-turbo,few-shot,political
weighted avg,0.8275911441136647,0.8275862068965517,0.8274999013651069,580.0,gpt-3.5-turbo,few-shot,political
exemplar,0.2582697201017812,0.2646675358539765,0.26142949130714743,767.0,google-flan-t5-xxl,few-shot,exemplar
nonexemplar,0.7319391634980988,0.7253886010362695,0.7286491601608706,2123.0,google-flan-t5-xxl,few-shot,exemplar
accuracy,0.6031141868512111,0.6031141868512111,0.6031141868512111,0.6031141868512111,google-flan-t5-xxl,few-shot,exemplar
macro avg,0.49510444179994,0.495028068445123,0.495039325734009,2890.0,google-flan-t5-xxl,few-shot,exemplar
weighted avg,0.6062282766174845,0.6031141868512111,0.6046500300533254,2890.0,google-flan-t5-xxl,few-shot,exemplar
apolitical,0.7013311148086523,0.5813793103448276,0.6357466063348417,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
political,0.6425206124852768,0.7524137931034482,0.6931385006353241,1450.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
accuracy,0.666896551724138,0.666896551724138,0.666896551724138,0.666896551724138,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
macro avg,0.6719258636469645,0.6668965517241379,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
weighted avg,0.6719258636469646,0.666896551724138,0.6644425534850829,2900.0,sentence-transformers-all-MiniLM-L6-v2,zero-shot,political
