,precision,recall,f1-score,support,models,tasks,columns
apolitical,0.7153163152053275,0.8920415224913495,0.7939636587619342,1445.0,gpt-3.5-turbo,few-shot,political
political,0.8566176470588235,0.6449826989619377,0.7358863008290564,1445.0,gpt-3.5-turbo,few-shot,political
accuracy,0.7685121107266436,0.7685121107266436,0.7685121107266436,0.7685121107266436,gpt-3.5-turbo,few-shot,political
macro avg,0.7859669811320755,0.7685121107266436,0.7649249797954953,2890.0,gpt-3.5-turbo,few-shot,political
weighted avg,0.7859669811320754,0.7685121107266436,0.7649249797954952,2890.0,gpt-3.5-turbo,few-shot,political
exemplar,0.3333333333333333,0.546284224250326,0.4140316205533596,767.0,gpt-4,few-shot,exemplar
not an exemplar,0.7868952847519902,0.605275553462082,0.6842385516506923,2123.0,gpt-4,few-shot,exemplar
accuracy,0.5896193771626298,0.5896193771626298,0.5896193771626298,0.5896193771626298,gpt-4,few-shot,exemplar
macro avg,0.5601143090426618,0.575779888856204,0.5491350861020259,2890.0,gpt-4,few-shot,exemplar
weighted avg,0.666520884496589,0.5896193771626298,0.6125261931207081,2890.0,gpt-4,few-shot,exemplar
exemplar,0.29603209986625056,0.8657105606258149,0.4411960132890366,767.0,gpt-3.5-turbo,few-shot,exemplar
not an exemplar,0.8408037094281299,0.2562411681582666,0.39277978339350184,2123.0,gpt-3.5-turbo,few-shot,exemplar
accuracy,0.4179930795847751,0.4179930795847751,0.4179930795847751,0.4179930795847751,gpt-3.5-turbo,few-shot,exemplar
macro avg,0.5684179046471902,0.5609758643920407,0.41698789834126926,2890.0,gpt-3.5-turbo,few-shot,exemplar
weighted avg,0.6962224552641294,0.4179930795847751,0.40562935028965247,2890.0,gpt-3.5-turbo,few-shot,exemplar
exemplar,0.2398753894080997,0.09974093264248704,0.14089661482159194,772.0,gpt-4,zero-shot,exemplar
not an exemplar,0.7305157037611477,0.8853383458646616,0.8005098789037604,2128.0,gpt-4,zero-shot,exemplar
accuracy,0.6762068965517242,0.6762068965517242,0.6762068965517242,0.6762068965517242,gpt-4,zero-shot,exemplar
macro avg,0.4851955465846237,0.49253963925357436,0.4707032468626762,2900.0,gpt-4,zero-shot,exemplar
weighted avg,0.5999038683540605,0.6762068965517242,0.6249162789480934,2900.0,gpt-4,zero-shot,exemplar
apolitical,0.7627230667547918,0.7986159169550173,0.7802569303583503,1445.0,gpt-4,few-shot,political
political,0.7886710239651417,0.7515570934256055,0.7696669029057406,1445.0,gpt-4,few-shot,political
accuracy,0.7750865051903114,0.7750865051903114,0.7750865051903114,0.7750865051903114,gpt-4,few-shot,political
macro avg,0.7756970453599668,0.7750865051903114,0.7749619166320454,2890.0,gpt-4,few-shot,political
weighted avg,0.7756970453599668,0.7750865051903114,0.7749619166320454,2890.0,gpt-4,few-shot,political
apolitical,0.7463722397476341,0.8158620689655173,0.7795716639209227,1450.0,gpt-3.5-turbo,zero-shot,political
political,0.7969581749049429,0.7227586206896551,0.7580470162748644,1450.0,gpt-3.5-turbo,zero-shot,political
accuracy,0.7693103448275862,0.7693103448275862,0.7693103448275862,0.7693103448275862,gpt-3.5-turbo,zero-shot,political
macro avg,0.7716652073262885,0.7693103448275862,0.7688093400978935,2900.0,gpt-3.5-turbo,zero-shot,political
weighted avg,0.7716652073262886,0.7693103448275862,0.7688093400978935,2900.0,gpt-3.5-turbo,zero-shot,political
apolitical,0.8983812949640287,0.6889655172413793,0.7798594847775177,1450.0,gpt-4,zero-shot,political
political,0.7477628635346756,0.9220689655172414,0.8258184064237184,1450.0,gpt-4,zero-shot,political
accuracy,0.8055172413793104,0.8055172413793104,0.8055172413793104,0.8055172413793104,gpt-4,zero-shot,political
macro avg,0.8230720792493522,0.8055172413793104,0.802838945600618,2900.0,gpt-4,zero-shot,political
weighted avg,0.8230720792493522,0.8055172413793104,0.8028389456006181,2900.0,gpt-4,zero-shot,political
apolitical,0.7962406015037594,0.7303448275862069,0.7618705035971223,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
political,0.7509554140127389,0.8131034482758621,0.780794701986755,1450.0,stabilityai-StableBeluga-13B,zero-shot,political
accuracy,0.7717241379310344,0.7717241379310344,0.7717241379310344,0.7717241379310344,stabilityai-StableBeluga-13B,zero-shot,political
macro avg,0.7735980077582492,0.7717241379310344,0.7713326027919387,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
weighted avg,0.773598007758249,0.7717241379310344,0.7713326027919386,2900.0,stabilityai-StableBeluga-13B,zero-shot,political
apolitical,0.7479725514660013,0.8268965517241379,0.7854569276121848,1450.0,google-flan-t5-xxl,zero-shot,political
political,0.8064764841942945,0.7213793103448276,0.7615580633418275,1450.0,google-flan-t5-xxl,zero-shot,political
accuracy,0.7741379310344828,0.7741379310344828,0.7741379310344828,0.7741379310344828,google-flan-t5-xxl,zero-shot,political
macro avg,0.7772245178301479,0.7741379310344827,0.7735074954770061,2900.0,google-flan-t5-xxl,zero-shot,political
weighted avg,0.777224517830148,0.7741379310344828,0.7735074954770061,2900.0,google-flan-t5-xxl,zero-shot,political
exemplar,0.2621276595744681,0.7979274611398963,0.3946188340807175,772.0,google-flan-t5-xxl,zero-shot,exemplar
not an exemplar,0.7163636363636363,0.18515037593984962,0.29424943988050783,2128.0,google-flan-t5-xxl,zero-shot,exemplar
accuracy,0.3482758620689655,0.3482758620689655,0.3482758620689655,0.3482758620689655,google-flan-t5-xxl,zero-shot,exemplar
macro avg,0.48924564796905223,0.49153891853987297,0.34443413698061265,2900.0,google-flan-t5-xxl,zero-shot,exemplar
weighted avg,0.5954428866804508,0.3482758620689655,0.3209684648193223,2900.0,google-flan-t5-xxl,zero-shot,exemplar
